"""
Langchain + MCP é›†æˆå®¢æˆ·ç«¯

è¿™ä¸ªæ¨¡å—å±•ç¤ºäº†å¦‚ä½•å°† Model Context Protocol é›†æˆåˆ° Langchain ä¸­ï¼Œ
å®ç° AI ä»£ç†é€šè¿‡æ ‡å‡† MCP åè®®è°ƒç”¨å¤–éƒ¨å·¥å…·ã€‚
"""

import json
import asyncio
from typing import Dict, Any, List, Optional
from langchain_core.language_models.llms import LLM
from langchain_core.callbacks.manager import CallbackManagerForLLMRun
from langchain.tools import Tool

# ä½¿ç”¨ç»å¯¹å¯¼å…¥
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import config
from mcp_client import MCPClient
from mcp_server import MCPServer
import requests

# åˆ›å»ºå…¨å±€ MCP å®ä¾‹ ä¿æŒ1å¯¹1çš„é“¾æ¥
mcp_server = MCPServer()
mcp_client = MCPClient(server=mcp_server)


class CustomLLM(LLM):
    """
    è‡ªå®šä¹‰ LLM ç±»
    """
    
    def __init__(self):
        super().__init__()
        # å°†å±æ€§å­˜å‚¨ä¸ºå†…éƒ¨å˜é‡ï¼Œé¿å…ä¸pydanticå†²çª
        self._api_url = f"{config.api_base_url}/chat/completions"
        self._headers = config.get_api_headers()
        self._model_name = config.model_name
        
        print(f"ğŸ¤– åˆå§‹åŒ– LLM: {self._model_name}")
    
    @property
    def _llm_type(self) -> str:
        return "custom_api"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        
        request_data = {
            "model": self._model_name,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 1000),
        }
        
        if stop:
            request_data["stop"] = stop
        
        try:
            response = requests.post(
                self._api_url,
                headers=self._headers,
                json=request_data,
                timeout=config.api_timeout
            )
            
            response.raise_for_status()
            response_data = response.json()
            
            if "choices" in response_data and len(response_data["choices"]) > 0:
                return response_data["choices"][0]["message"]["content"]
            else:
                raise ValueError("API å“åº”æ ¼å¼é”™è¯¯")
                
        except Exception as e:
            raise Exception(f"LLM è°ƒç”¨å¤±è´¥: {str(e)}")


class MCPToolWrapper:
    """
    MCP å·¥å…·åŒ…è£…å™¨
    
    è¿™ä¸ªåŒ…è£…å™¨é€šè¿‡æ ‡å‡† MCP åè®®ä¸ MCP Server é€šä¿¡
    """
    
    def __init__(self, tool_name: str, tool_info: Dict[str, Any]):
        """
        åˆå§‹åŒ–çœŸæ­£çš„ MCP å·¥å…·åŒ…è£…å™¨
        
        Args:
            tool_name (str): å·¥å…·åç§°
            tool_info (Dict[str, Any]): å·¥å…·ä¿¡æ¯
        """
        self.tool_name = tool_name
        self.tool_info = tool_info
    
    def __call__(self, **kwargs) -> str:
        """
        é€šè¿‡ MCP åè®®è°ƒç”¨å·¥å…·
        
        Args:
            **kwargs: å·¥å…·å‚æ•°
            
        Returns:
            str: å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            # ğŸ”‘ å…³é”®ï¼šè¿™é‡Œä½¿ç”¨çœŸæ­£çš„ MCP åè®®è¿›è¡Œé€šä¿¡
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰äº‹ä»¶å¾ªç¯åœ¨è¿è¡Œ
            try:
                loop = asyncio.get_running_loop()
                # å¦‚æœæœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œä½¿ç”¨ asyncio.create_task
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, mcp_client.call_tool(self.tool_name, kwargs))
                    result = future.result()
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                result = asyncio.run(mcp_client.call_tool(self.tool_name, kwargs))
            
            if result["success"]:
                output = f"âœ… MCP å·¥å…· '{self.tool_name}' æ‰§è¡ŒæˆåŠŸ\n"
                output += f"ğŸ“¡ é€šè¿‡ JSON-RPC 2.0 åè®®è°ƒç”¨\n"
                output += f"ç»“æœ: {json.dumps(result['result'], ensure_ascii=False, indent=2)}"
                return output
            else:
                output = f"âŒ MCP å·¥å…· '{self.tool_name}' æ‰§è¡Œå¤±è´¥\n"
                output += f"é”™è¯¯: {result['error']}"
                return output
                
        except Exception as e:
            return f"âŒ MCP å·¥å…·è°ƒç”¨å¼‚å¸¸: {str(e)}"


class MCPLangchainClient:
    """
    é›†æˆ MCP åè®®çš„ Langchain å®¢æˆ·ç«¯
    
    è¿™ä¸ªç±»å±•ç¤ºäº†å¦‚ä½•å°†æ ‡å‡†çš„ MCP åè®®é›†æˆåˆ° Langchain ä¸­
    """
    
    def __init__(self):
        """åˆå§‹åŒ– MCP Langchain å®¢æˆ·ç«¯"""
        
        self.llm = CustomLLM()
        self.mcp_initialized = False
        self.tools = []
        
        print(f"ğŸ”— çœŸæ­£çš„ MCP Langchain å®¢æˆ·ç«¯åˆå§‹åŒ–ä¸­...")
    
    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ– MCP è¿æ¥
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        
        try:
            # åˆå§‹åŒ– MCP å®¢æˆ·ç«¯
            success = await mcp_client.initialize()
            
            if not success:
                print("âŒ MCP å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
                return False
            
            self.mcp_initialized = True
            
            # åˆ›å»º Langchain å·¥å…·
            await self._create_tools()
            
            print(f"âœ… çœŸæ­£çš„ MCP Langchain å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œé›†æˆäº† {len(self.tools)} ä¸ªå·¥å…·")
            return True
            
        except Exception as e:
            print(f"âŒ MCP Langchain å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    async def _create_tools(self) -> None:
        """åˆ›å»º Langchain å·¥å…·ï¼ˆåŸºäºçœŸæ­£çš„ MCP åè®®ï¼‰"""
        
        self.tools = []
        
        # ä» MCP å®¢æˆ·ç«¯è·å–å¯ç”¨å·¥å…·
        available_tools = mcp_client.get_available_tools()
        
        for tool_info in available_tools:
            tool_name = tool_info["name"]
            
            # åˆ›å»ºçœŸæ­£çš„ MCP å·¥å…·åŒ…è£…å™¨
            wrapper = MCPToolWrapper(tool_name, tool_info)
            
            # åˆ›å»º Langchain Tool
            langchain_tool = Tool(
                name=tool_name,
                description=tool_info["description"],
                func=wrapper
            )
            
            self.tools.append(langchain_tool)
            print(f"ğŸ”§ é›†æˆçœŸæ­£çš„ MCP å·¥å…·: {tool_name}")
    
    async def chat(self, message: str) -> Dict[str, Any]:
        """
        ä¸é›†æˆäº†çœŸæ­£ MCP çš„ Agent å¯¹è¯
        
        Args:
            message (str): ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            Dict[str, Any]: å›å¤ç»“æœ
        """
        
        if not self.mcp_initialized:
            return {
                "success": False,
                "error": "MCP å®¢æˆ·ç«¯æœªåˆå§‹åŒ–",
                "output": "è¯·å…ˆåˆå§‹åŒ– MCP è¿æ¥"
            }
        
        try:
            print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
            print("ğŸ¤– é€šè¿‡çœŸæ­£çš„ MCP åè®®å¤„ç†...")
            
            result = await self._process_with_mcp(message)
            
            print(f"ğŸ¤– åŠ©æ‰‹: {result['output']}")
            
            return result
            
        except Exception as e:
            error_msg = f"MCP å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            
            return {
                "success": False,
                "error": error_msg,
                "output": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚"
            }
    
    async def _process_with_mcp(self, message: str) -> Dict[str, Any]:
        """ä½¿ç”¨çœŸæ­£çš„ MCP åè®®å¤„ç†æ¶ˆæ¯"""
        
        # æ„å»ºå·¥å…·æè¿°ï¼ˆåŒ…å«å‚æ•°ä¿¡æ¯ï¼‰
        tools_desc = []
        for tool in self.tools:
            if tool.name == "write_file":
                tools_desc.append(f"- {tool.name}: {tool.description} (å‚æ•°: path=æ–‡ä»¶è·¯å¾„, content=æ–‡ä»¶å†…å®¹)")
            elif tool.name == "read_file":
                tools_desc.append(f"- {tool.name}: {tool.description} (å‚æ•°: path=æ–‡ä»¶è·¯å¾„)")
            elif tool.name == "calculate":
                tools_desc.append(f"- {tool.name}: {tool.description} (å‚æ•°: expression=æ•°å­¦è¡¨è¾¾å¼)")
            elif tool.name == "get_current_time":
                tools_desc.append(f"- {tool.name}: {tool.description} (æ— å‚æ•°)")
            else:
                tools_desc.append(f"- {tool.name}: {tool.description}")
        tools_desc = "\n".join(tools_desc)
        
        # æ„å»ºæç¤º
        prompt = f"""ç”¨æˆ·è¯·æ±‚: {message}

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨çœŸæ­£ Model Context Protocol (MCP) çš„ç³»ç»Ÿï¼

ğŸ”§ å¯ç”¨çš„ MCP å·¥å…·:
{tools_desc}

ğŸ’¡ MCP åè®®ç‰¹ç‚¹:
- åŸºäº JSON-RPC 2.0 æ ‡å‡†
- Client-Server æ¶æ„é€šä¿¡
- æ ‡å‡†åŒ–å·¥å…·å‘ç°å’Œè°ƒç”¨
- å®‰å…¨çš„ç½‘ç»œåè®®

è¯·åˆ†æç”¨æˆ·éœ€æ±‚ï¼š
1. å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·è¯´æ˜è¦ä½¿ç”¨çš„ MCP å·¥å…·åŠåŸå› 
2. ç„¶åæŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
   MCP_TOOL: [å·¥å…·åç§°]
   MCP_PARAMS: {{"å‚æ•°å": "å‚æ•°å€¼"}}
3. å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å›å¤ç”¨æˆ·

è¯·å¼€å§‹åˆ†æå¹¶å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼š"""

        # è°ƒç”¨ LLM
        response = self.llm(prompt)
        
        intermediate_steps = []
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ MCP å·¥å…·è°ƒç”¨
        if "MCP_TOOL:" in response and "MCP_PARAMS:" in response:
            try:
                # è§£æ MCP å·¥å…·è°ƒç”¨
                lines = response.split('\n')
                tool_name = None
                params = {}
                
                for line in lines:
                    if line.startswith("MCP_TOOL:"):
                        tool_name = line.replace("MCP_TOOL:", "").strip()
                    elif line.startswith("MCP_PARAMS:"):
                        try:
                            params_str = line.replace("MCP_PARAMS:", "").strip()
                            params = json.loads(params_str)
                        except:
                            params = {}
                
                # æ‰§è¡Œ MCP å·¥å…·
                if tool_name:
                    tool_names = [tool.name for tool in self.tools]
                    if tool_name in tool_names:
                        tool = next(tool for tool in self.tools if tool.name == tool_name)
                        
                        print(f"ğŸ“¡ é€šè¿‡ MCP åè®®æ‰§è¡Œå·¥å…·: {tool_name}")
                        print(f"ğŸ“¥ MCP å‚æ•°: {params}")
                        
                        # ğŸ”‘ å…³é”®ï¼šè¿™é‡Œé€šè¿‡çœŸæ­£çš„ MCP åè®®è°ƒç”¨å·¥å…·
                        tool_result = tool.func(**params)
                        
                        intermediate_steps.append({
                            "mcp_tool": tool_name,
                            "mcp_params": params,
                            "mcp_result": tool_result,
                            "protocol": "JSON-RPC 2.0"
                        })
                        
                        # ç”Ÿæˆæœ€ç»ˆå›å¤
                        final_prompt = f"""MCP å·¥å…·æ‰§è¡Œç»“æœï¼š
{tool_result}

åŸå§‹ç”¨æˆ·è¯·æ±‚ï¼š{message}

è¿™ä¸ªç»“æœæ˜¯é€šè¿‡çœŸæ­£çš„ Model Context Protocol (MCP) è·å¾—çš„ï¼š
- ä½¿ç”¨äº† JSON-RPC 2.0 åè®®
- Client-Server æ¶æ„é€šä¿¡
- æ ‡å‡†åŒ–çš„å·¥å…·è°ƒç”¨æ¥å£

è¯·æ ¹æ® MCP å·¥å…·æ‰§è¡Œç»“æœï¼Œç”Ÿæˆä¸€ä¸ªå‹å¥½ã€æœ‰ç”¨çš„å›å¤ç»™ç”¨æˆ·ï¼š"""
                        
                        final_response = self.llm(final_prompt)
                        
                        return {
                            "success": True,
                            "output": final_response,
                            "mcp_steps": intermediate_steps,
                            "protocol_used": "Model Context Protocol (JSON-RPC 2.0)"
                        }
            
            except Exception as e:
                print(f"âš ï¸ MCP å·¥å…·è°ƒç”¨è§£æå¤±è´¥: {str(e)}")
        
        # ç›´æ¥å›å¤
        return {
            "success": True,
            "output": response,
            "mcp_steps": intermediate_steps,
            "protocol_used": "Direct LLM Response"
        }
    
    def get_mcp_info(self) -> Dict[str, Any]:
        """è·å– MCP åè®®ä¿¡æ¯"""
        
        client_info = mcp_client.get_client_info()
        
        return {
            "mcp_protocol": "Model Context Protocol (JSON-RPC 2.0)",
            "mcp_version": "2024-11-05",
            "client_info": client_info,
            "tools_count": len(self.tools),
            "initialized": self.mcp_initialized,
            "standards_compliance": {
                "json_rpc": "2.0",
                "client_server_architecture": True,
                "standardized_tool_discovery": True,
                "secure_communication": True
            }
        }


# åˆ›å»ºçœŸæ­£çš„ MCP Langchain å®¢æˆ·ç«¯å®ä¾‹
mcp_langchain_client = MCPLangchainClient()

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œè¿›è¡Œæµ‹è¯•
if __name__ == "__main__":
    import asyncio
    
    async def test_mcp_langchain():
        """æµ‹è¯•çœŸæ­£çš„ MCP Langchain é›†æˆ"""
        
        print("ğŸ§ª æµ‹è¯•çœŸæ­£çš„ MCP + Langchain é›†æˆ")
        print("="*60)
        
        # åˆå§‹åŒ–
        success = await mcp_langchain_client.initialize()
        if not success:
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ˜¾ç¤º MCP ä¿¡æ¯
        mcp_info = mcp_langchain_client.get_mcp_info()
        print(f"ğŸ“‹ MCP åè®®ä¿¡æ¯:")
        print(f"   åè®®: {mcp_info['mcp_protocol']}")
        print(f"   ç‰ˆæœ¬: {mcp_info['mcp_version']}")
        print(f"   å·¥å…·æ•°é‡: {mcp_info['tools_count']}")
        print(f"   æ ‡å‡†åˆè§„: JSON-RPC 2.0 âœ…")
        
        # æµ‹è¯•å¯¹è¯
        test_messages = [
            "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ ä½¿ç”¨çš„ MCP åè®®",
            "è¯·è·å–å½“å‰æ—¶é—´",
            "è¯·è®¡ç®— 25 * 4 + 10 çš„ç»“æœ",
            "è¯·åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ mcp_demo.txtï¼Œå†…å®¹æ˜¯'è¿™æ˜¯é€šè¿‡çœŸæ­£çš„ MCP åè®®åˆ›å»ºçš„ï¼'"
        ]
        
        for i, message in enumerate(test_messages, 1):
            print(f"\nğŸ” æµ‹è¯• {i}: {message}")
            print("-" * 50)
            
            result = await mcp_langchain_client.chat(message)
            
            if result["success"]:
                print(f"âœ… æˆåŠŸ")
                if "mcp_steps" in result and result["mcp_steps"]:
                    print(f"ğŸ“¡ ä½¿ç”¨äº† MCP åè®®: {result['protocol_used']}")
                    for step in result["mcp_steps"]:
                        print(f"   MCP å·¥å…·: {step['mcp_tool']}")
                        print(f"   åè®®: {step['protocol']}")
            else:
                print(f"âŒ å¤±è´¥: {result['error']}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_mcp_langchain())
